+++
title = "AI Agent UX"
description = "Augmentation is composed of smaller automations. AI helps generate levels of abstraction."
date = 2024-05-12T00:00:00Z
#updated = 2022-11-10
#weight = 0
#slug = "future post"
#path = "/launch"
#draft = true

[taxonomies]
tags = ["llm", "agentic_ai", "ai"]

[extra]
ToC = false
+++

## AI + UIs

{{ youtube(id="PAy_GHUAICw", autoplay=false, class="youtube") }}

<sup>"Climbing the Ladder of Abstraction" talk by Amelia Wattenberger of Adept.ai</sup>

Often when people talk about building interfaces with AI, they refer to these two distinct categories:

|Automate | Augment |
|---------|---------|
|tedious  |creative |
|boring   |nuanced  |
|example: copy + pasting into a table | example: analysing data |

Let's reframe the above dichotomy below.

## **Augmentation** is composed of smaller **automations**

(copy + pasting into a table â†’ analysing data)

## Why chatbots are not the future

I think these flexible general tools like calculators and chatbots (like ChatGPT) are wonderful. But then adding a structured interface around them makes them so much more powerful for many use cases.

What we want is something where the tech behind chatbots is embedded into the interfaces where we're still driving but the model is automating away the smaller tasks we find so frustrating. What might these interfaces look like?

## The ladder of abstraction

Examples: Google Maps interface is a well designed abstraction.

## Combine the two concepts

```
    Augmentation is composed of smaller automations
                           +
Traversing the ladder of abstraction for different tasks
```

How might this look in a more general product, [Adept](https://www.adept.ai/).
Adept applies AI to solve real work problems. Adept train SotA **multi-modal** models to use software, **read screens**, and take actions just like a person does. Their goal is to make knowledge work easier (any work on a computer).

## Knowledge Work

What people do day to day at their jobs we found that much of knowledge work involves getting information, transforming or reasoning about it and then acting on that information.

Given this really common workflow, <!--one of the things we've been thinking about is--> what might it mean to **zoom out on any piece of information**. Sketches where we're exploring what that might feel like or what it might enable us to do.

(a completely hypothetical situation: let's say we're going to a conference in San Francisco and we go to Airbnb to find listings near the venue.)

The argument: we can use AI to generate these different levels, glue them together and make it easy to move between them.
Adept think this could completely change the way that we work with information.

## Summary

To sum up, there are two take away:

1. Automations --> augmentation
2. AI helps generate levels of abstraction

Key idea: agent (interface) without chat (text generation system)
